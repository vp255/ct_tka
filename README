PROMPT

[CoreDev Candidate Programming Project]

In broad terms, algorithmic trading strategies observe and react to three types of external input, specifically: (1) Market data events, (2) Order execution events, and (3) Changes to the value of the system clock. Focusing on the last category, the ability to track and appropriately react to the passage of time is crucial for many strategies. As an example, if a strategy decides to act on a predictive signal and enter into a position, it may choose to set up a timer allowing it to exit the position if the prediction does not realize within some predetermined time interval.



In this assignment, your goal is to implement a high-performance TimerService module that accepts timer registration requests from a hypothetical single-threaded HFT strategy and manages the dispatch of timer event callbacks.
Attached, please find a copy of the header file (TimerService.h) containing the declaration of the TimerService class and the specification of its public interface. DemoTimerServiceClient.cpp contains a minimal client application that illustrates the usage of the TimerService interface.



Since TimerService will be used in latency-sensitive strategies, runtime efficiency is a top-level concern and we challenge you to come up with the most efficient implementation under the following assumptions:

  1. TimerService::advanceClock() will be called from the strategy's main event dispatch loop quite frequently (at least once per millisecond).

  2. Calls to TimerService::setTimer() and setRepeatingTimer() will be much less frequent and most of them will happen at startup time.

  3. The total number of simultaneously-active timers managed by a single TimerService instance will not exceed 1024.

  4. The vast majority of the repeating timers will have periodicity ranging from 10ms to 10sec.



The primary target for performance optimization is the execution time of TimerService::advanceClock(). A call to this method that does not result in dispatching of any timer callbacks should incur as little latency as possible.


####

built using gcc 9.3.1 on fedora 31

to run tests, in this directory execute:

   make; ./build/apps/timer_service_tests
   
to clean:
   make clean;
   
####

Assumptions:


####

Design decisions:  I thought of using 3 possible implementations

1) Using a std::priority_queue to store structs of callback information, and an std::unordered_set<int> of id's to store canceled callbacks. We would lazily delete items as they come up in the priority_queue by checking the std::unordered_map. Upon encountering repeated timers, reinsert into the priority_queue

pros: locality of reference on reading the priority_queue due to the contiguous underlying std::vector storing the data. 
cons: worse theoretical runtime, two data structures 
runtime: insertion O(log(n)), pop(): O(log(n)), erasing O(1) lazily,

2) Using a std::map to store structs of callback information, and upon deletion, just delete from the map. Upon encountering repeated timers, reinsert into the map.

pros: good theoretical runtime, one data structure
cons: bad locality of reference
runtime: insertion: log(n), deleting from the begin() iterator: O(1) amortized, erasing (log(n)), 

3) Using a customized circular buffer flat_set structure, where one would keep track of the head and tail of the sorted range of
numbers, and using an std::unordered_set<int> to keep a track of lazily canceled timers.

pros: good locality of reference and runtime
cons: complicated implementation
runtime: Insertion O(n), popping off from inspecting the front by advancing the head pointer O(1), eagerly deleting O(n) which is better than the lazy deletion O(1) according to testing

Went with approach 3.

####

Other notes:

I opted to have an extra boolean in our TimerServiceElement type because it did
not increase the overhead of the size due to padding, and the strategy of
setting the id to NO_TIMER_ID does not work in the case of a callback modifying
that property, because the data structure uses ID to help sort, so changing it
to -1 would be destructive. I also opted to use this field instead of having a
separate std::unordered_map of canceled_timers because this would improve
locality of reference during lookups.

I chose the size to be 2 * 1024 = 2048 because a lazily deleted timer still
contributes to capacity until it is processed. So if we have 1 timer, cancel it,
then insert 1024 we should not have a problem. However it is still possible to
have overflow problems if we have 1024 canceled but not processed timers, which
is a rare case.

